# Agent Smith

Agent Smith is a full-stack AI backend experiment that coordinates multiple lightweight agents to plan study goals, research resources, and guide learners via FastAPI endpoints. The system prioritizes open, local-first tooling with optional gateways to hosted LLMs.

## Project Structure

```
agent-smith/
  pyproject.toml
  README.md
  prompts/
    setup.txt
  agent_smith/
    __init__.py
    app.py
    config.py
    models.py
    db.py
    logging_config.py
    orchestrator.py
    agents/
      __init__.py
      base.py
      planner.py
      researcher.py
      curator.py
      tutor.py
    tools/
      __init__.py
      web.py
      vector.py
      llm.py
```

## Configuration

Agent Smith reads configuration values from environment variables (or a local
`.env` file) via `pydantic-settings`:

- `AGENT_SMITH_ENV` — controls runtime mode (`development`, `staging`, `production`).
- `OPENAI_API_KEY` — optional key to enable OpenAI-powered completions.
- `AGENT_SMITH_SQLITE_PATH` — filesystem location for the primary SQLModel DB.
- `AGENT_SMITH_CHROMA_PATH` — directory for persisted ChromaDB collections.

Defaults place both databases under `./var/`, and missing directories are
created automatically during startup.

## Data Model

| Table | Purpose |
| --- | --- |
| `learning_goals` | Top-level objectives, learner context, and lifecycle state. |
| `plan_items` | Daily/sequence-specific action items generated by the planner. |
| `resources` | Curated articles, videos, or notes linked to each plan item. |
| `quiz_items` | Formative assessments with answer tracking and feedback. |
| `episodes` | Daily orchestration snapshots, summaries, and reflections. |

Every model is defined with SQLModel for seamless SQLite + FastAPI integration.

## Memory Systems

Agent Smith uses SQLite for structured progress tracking and ChromaDB for
semantic memory. A lightweight hashing-based embedding function keeps the
vector store fully local while still supporting similarity search APIs. Helper
functions in `agent_smith.tools.vector` expose `upsert_resources` and
`search_resources` utilities consumed by researcher/curator agents.

## Tooling

- `duckduckgo_search` — general-purpose web search without API keys.
- `wikipedia_search` — structured topic lookups from the Wikimedia REST API.
- `arxiv_search` — Atom feed parser for research-heavy study goals.

Each helper returns normalized `SearchResult` objects so higher-level agents can
mix-and-match sources without custom parsing logic.

## Agent Architecture

```
Learner Goal
   |
   v
+----------+      +-------------+      +-------------+      +-----------+
| Planner  | ---> | Researcher  | ---> |  Curator    | ---> |   Tutor   |
+----------+      +-------------+      +-------------+      +-----------+
   |                   |                    |                    |
 plan items        raw resources       summaries + ranks      quizzes + tips
```

- **Planner** turns a goal + reflections into actionable daily tasks.
- **Researcher** maps each task to open-web results and seeds the vector store.
- **Curator** summarizes and ranks resources for clarity.
- **Tutor** produces formative quizzes and coaching messages.

All agents share the same `Agent` base class and LLM abstraction, so swapping in
OpenAI or local providers only requires configuration changes.

## Getting Started

1. Create a virtual environment and install dependencies:

   ```bash
   python -m venv .venv
   source .venv/bin/activate
   pip install -e .[dev]
   ```

2. Launch the API:

   ```bash
   uvicorn agent_smith.app:app --reload
   ```

3. Interact via `curl`, `httpie`, or the interactive docs at
   `http://127.0.0.1:8000/docs`.

## API Reference

- `GET /health` — readiness probe.
- `POST /goals` — create a learning goal payload `{title, description, learner_profile, target_days}`.
- `GET /goals/{id}` — fetch goal details.
- `GET /goals/{id}/plan?day=<n>` — list plan items for the goal (optional day filter).
- `POST /goals/{id}/run/{day}` — execute the full agent pipeline for the specified day.
- `GET /goals/{id}/quiz/{day}` — fetch the generated quiz items.
- `POST /quiz/{id}/answer` — submit an answer and receive grading feedback.

## Self-Correction & Reflection

Each daily run closes with a reflection generated by the planning agent's LLM
prompt. The summary is persisted on the `episodes` table and automatically
annotates future plan items (notes + task focus) so the learner sees how past
insights influence upcoming work. When quiz answers are submitted, the tutor
agent performs a lightweight lexical overlap check to grade correctness and
stores feedback for future review.

## Design Goals & Philosophy

- Prefer local-first tooling with graceful fallbacks to hosted services.
- Keep agents transparent: every stage saves structured summaries in the DB.
- Embrace incremental iteration—pipelines are deterministic and resumable.

## Extending Agent Smith

- Plug in additional tool adapters under `agent_smith.tools` (e.g., code
  sandboxes, notebook runners).
- Swap LLM providers by implementing a new `BaseLLM` subclass or enabling the
  OpenAI extra.
- Add specialized agents (e.g., `ReviewerAgent`) by reusing the base class.

## Next Steps

1. Add an HTMX or React micro-frontend for interactive study sessions.
2. Persist agent message traces for observability and playback.
3. Expand quiz grading with semantic similarity metrics or rubric scoring.

## Limitations

- Local heuristic LLM responses are deterministic and may lack creativity.
- Web search APIs can change formatting, so parsing logic should be hardened.
- Current evaluation relies on simple lexical overlap rather than embeddings.

## License

Distributed under the MIT License. See [LICENSE](LICENSE) for details.
